Niche Models
============

Introduction
------------

The following R markdown file explains the steps needed to calculate niche overlap between the extant Ungulates. 
Here we explain two different approaches to calculate the niche per species: 

1. Maxent species distribution models, and 
2. Outlying Mean Index (OMI) and how to calculate their overlap.

The following libraries and scripts need to be loaded:

```{r libraries}
library(raster, quietly = T)
library(knitr, quietly = T)
library(maxent, quietly = T)
library(maps, quietly = T)
library(rJava, quietly = T) 
library(maptools, quietly = T)
library(jsonlite, quietly = T)
library(caret, quietly = T)
library(ENMeval, quietly = T)
library(repmis, quietly = T)
library(CoordinateCleaner, quietly = T)
library(dismo, quietly = T) 
library(virtualspecies, quietly = T)
library(sp, quietly = T)
library(rgeos, quietly = T)
library(ape, quietly = T)
library(adehabitatMA, quietly = T)
library(ade4, quietly = T)
library(raster, quietly = T)
library(SDMTools, quietly = T)
library(factoextra, quietly = T)
library(ecospat, quietly = T)
library(phytools, quietly = T)

# our local code. the goal is that this will eventually be properly portable code that lives
# inside the ./R folder of the repository
source("MaxEnt_function.R")
```

In addition, here we define the global variables that we will reuse throughout the code

```{r globals}
# this is the location of the root directory of the git repository in the local file system.
# normally you would be running the code from within rstudio, using a project that is initialized
# within that directory, so the working directory should automatically be set.
REPO_HOME <- paste(getwd(),'/../',sep='')
```

To calculate niches and niche overlap environmental data and occurrence data per species are needed.

The environmental data used in this research are based on climatic variables, topography and soil 
characteristics. Climatic information about the present was extracted from the widely used Bioclim 
dataset, which includes 19 bioclimatic layers. The datasets contain information such as precipitation 
in the driest quarter or maximum temperatures of the coldest month and are constructed based on 
monthly remote sensing data between 1950 and 2000 (Hijmans et al., 2005, Title et al., 2018). The 
dataset can directly be downloaded with the getData() function from the raster package. It is also 
possible to adjust the spatial resolution res=2.5 to 30 seconds, 5 minutes and 10 minutes.

```{r getdata}
# This function from the raster package loads bioclimatic layers. It first attempts to do this
# from files in data/GIS/wc10, but if these are not found it will attempt to download them
# and cache them locally. Since the files are small enough to commit to github we will normally
# have these files already. This could change if we move to a resolution that is finer than 10
# arcminutes, as the layer files will then grow above 10MB.
currentEnv1 = raster::getData(
  "worldclim", 
  var="bio", 
  res=10, 
  path=paste(REPO_HOME, '/data/GIS', sep=''), 
  download=T
)
```

The other environmental datasets that we used are the new ENVIREM variables that give additional 
climatic information to the Bioclim datasets. We used median elevation variables from the Harmonized 
World Soil Database (HWSD), which are based on NASA’s Shuttle Radar Topographic Mission to calculate 
worldwide slope and aspect. We used indirect height measures such as slope and aspect because the 
height variables are directly correlated with the temperature Bioclim datasets. To capture soil 
characteristics, we used organic carbon, pH CaCL, bulk density and clay percentage datasets obtained 
from the land-atmosphere interaction research group at Sun Yat-sen University.

The additional environmental datasets that we used for this research can be downloaded from our 
dropbox folder at a spatial resolution of 5 and 10 minutes.

```{r add_layers}
# The location of the TIFF file with the stacked layers described directly above
totalstack.tif <- paste(REPO_HOME, '/data/GIS/Totalstack.tif', sep = '')

# This file is too large to keep under git, so this download is likely to happen at least once
if (!file.exists(totalstack.tif)) {

  # With the ?dl=1 argument the file is downloaded directly and stored as the temporary file
  download.file("https://www.dropbox.com/s/nlfe349hykg9pfs/Totalstack.tif?dl=1", totalstack.tif, quiet = T)
}

# load the file contents, assign layer names, add to environment
soilproperties <- stack(totalstack.tif)
names(soilproperties) <- c(
  "Aspect_10deg",
  "BulkDensity_10min",
  "ClayPercentage_10min",
  "current_10arcmin_annualPET",
  "current_10arcmin_aridityIndexThornthwaite",
  "current_10arcmin_climaticMoistureIndex",
  "current_10arcmin_continentality",
  "current_10arcmin_embergerQ",
  "current_10arcmin_growingDegDays0",
  "current_10arcmin_growingDegDays5",
  "current_10arcmin_maxTempColdest",
  "current_10arcmin_minTempWarmest",
  "current_10arcmin_monthCountByTemp10",
  "current_10arcmin_PETColdestQuarter",
  "current_10arcmin_PETDriestQuarter",
  "current_10arcmin_PETseasonality",
  "current_10arcmin_PETWarmestQuarter",
  "current_10arcmin_PETWettestQuarter",
  "current_10arcmin_thermicityIndex",
  "OrganicCarbon_10min",
  "PhCaCL_10min",
  "slope_10deg"
)
currentEnv <- stack(soilproperties, currentEnv1)
```

The occurrence datasets are needed to extract useful environmental information per species. The 
segment below reads a list of the species of interest from the `/data/filtered/taxa.txt` file. From 
this list we construct paths to input and output files per species. This way, we can work incrementally,
and cache intermediate results, such as maps of raw occurrence data, maxent models, model predictions,
and global projections.

```{r load_taxa}
# read listing
taxa <- scan(paste(REPO_HOME, "/data/filtered/taxa.txt", sep = ""), sep = "\n", what = character())

# make output directories, if needed
for ( i in 1:length(taxa) ) {
  taxon.dir.name <- sprintf('%s/results/per_species/%s/', REPO_HOME, taxa[i])
  if(!dir.exists(taxon.dir.name)) {
    dir.create(taxon.dir.name, recursive = T)
  }
}
rm(i,taxon.dir.name)
```

Below, the raw occurrence data are plotted on a map, which goes to `/results/per_species/<taxon>/occurrences.png`:

```{r plot_points}
data(wrld_simpl)
for ( i in 1:length(taxa) ) {

  # construct the name of the occurrences file for the current taxon
  taxon <- taxa[i]
  occ.map.file <- sprintf('%s/results/per_species/%s/occurrences.png', REPO_HOME, taxon)
  
  # generate the map
  if(!file.exists(occ.map.file)) {
  
    # create the path for the file whose occurrences you want to plot, then load occurrences as CSV
    csv.file <- sprintf('%s/data/filtered/%s.csv', REPO_HOME, taxon)
    occ <- read.csv(csv.file, header = T)
    lon <- occ$decimal_longitude
    lat <- occ$decimal_latitude

    # plot a simple world map
    png(file = occ.map.file)
    plot(
      wrld_simpl, 
      axes=TRUE, 
      xlim=c(min(lon)-5,max(lon)+5), 
      ylim=c(min(lat)-5,max(lat)+5), 
      col="grey", 
      main=sprintf('Raw occurrences for %s',taxon)
    )
    points(lon, lat, col="orange", pch=20, cex=0.75)
    box()
    dev.off()
  }
}
rm(i,occ.map.file,taxon,wrld_simpl)
```

Maxent: species distribution model
----------------------------------

For this research we used the Maximum Entropy (MaxEnt) machine learning algorithm version 3.3.3 to 
construct SDMs for all available species. Previous research has demonstrated that the MaxEnt technique 
performs well when using presence only data to estimate the relationships between environmental 
predictors and the occurrences of species (Elith et al., 2011, Philips et al., 2006, Tognelli et al., 2009, 
Conolly et al., 2012). The widely used machine learning algorithm is very efficient in the complex 
handling of response and predictor variable interactions and works well with little occurrence data 
points (Elith et al., 2011, Elith et al., 2006, Wisz et al., 2008).

Before the construction of the maxent model the environmental rasters are cropped to the extent 
of the occurrence points for a specific species + a buffer around the total extent. Buffers that 
are too small can result in underestimations of edge effects while buffers that are too large 
have the risk of losing track of favorable environmental conditions due to noise. In this research 
we base the extent of the buffer on the maximum distribution between two occurrence points, in 
this way we account for species with a wide distribution and species with a small distribution. 
The cropped environmental data are checked for collinearity, because only uncorrelated environmental 
raster layers can be used in the SDM (Dormann et al., 2013, Reas & Aguirre-Gutierrez, 2018). To 
remove correlated layers the removeCollinearity function in the virtualspecies version 1.4-4 R 
package was used (Leroy et al., 2016). Environmental variables with a Pearson’s R correlation 
coefficients above 0.7 were grouped and one variable within this group was randomly chosen, 
resulting in a raster stack with only uncorrelated environmental rasters.

Afterwards the occurrence dataset is split in k-fold partitions: a training dataset containing 
75% of the data and a test dataset containing 25% of the data. The maxent model is constructed 
using the maxent function from the dismo R package (Hijmans & Elith, 2013). The function extracts 
abiotic environmental data for the training occurrence locations and 1000 random sampled 
background locations, resulting in a model maxent object that can be used to predict which other 
locations are suitable.

To assess the model performance we used the area under the receiver operating curve (ROC), also 
known as the AUC, which is often used to estimate the ability of models (Fourcade et al., 2014). 
The AUC was interpreted as the probability that a randomly chosen “presence point”, the location 
of a species occurrence, has a higher predicted probability of occurrence than a randomly chosen 
absence point (Reas & Aguirre-Gutierrez, 2018). To compare a presence point to an absence point 
1000 absence points were randomly sampled within the study area. The test occurence datasets were 
used to evaluate the model performance with the evaluate function in the dismo R package 
(Hijmans & Elith, 2013). Only SDMs with an AUC value higher than 0.7 were used in the further steps, 
since these models are generally accepted as useful models (Swets et al., 2000).

The script below shows a loop that automatically loops through each species in the list and 
separates them into two groups: 

1. the models with a high accuracy and, 
2. the models with a low accuracy. 

The Maxent function used in this loop can be viewed and adapted in our Github repository in this [script](https://github.com/naturalis/trait-geo-diverse-ungulates/blob/master/script/MaxEnt_function.R).

```{r maxent1}

# first we created two empty lists, one list for models with a low accuracy (AUC below 0.7) and one 
# list for models with a high accuracy (AUC above 0.7)
list_species_model_low_accuracy <- list()
list_species_model_high_accuracy <- list()

# iterate over n species
for (i in 1:length(taxa)) {
  name <- taxa[i]
  valid.model.file <- sprintf('%s/results/per_species/%s/valid_maxent_model.rda', REPO_HOME, name)
  invalid.model.file <- sprintf('%s/results/per_species/%s/invalid_maxent_model.rda', REPO_HOME, name)
  
  # check if we have the model cached
  if(!file.exists(valid.model.file) && !file.exists(invalid.model.file)) {
    message(name)

    # set the extent for the training model with a buffer of 5 lon and lat
    csv.file <- sprintf('%s/data/filtered/%s.csv', REPO_HOME, name)
    species_occurence <- read.csv(csv.file, header = T)
    species_model <- Maxent_function(species_occurence, currentEnv)

    # validate the model with the test data
    # to construct an AUC model we need random points
    random <- randomPoints(species_model[[2]], 1000)
    Validation_species <- evaluate(p=species_model[[3]], a=random, x=species_model[[2]], model=species_model[[1]])

    # create two stacks one with the models with a low accuracy <0.7 and one with a high accuracy >0.7
    model <- species_model[[1]]
    if (Validation_species@auc > 0.7) {
      list_species_model_high_accuracy[[name]] <- model
      save(model, file = valid.model.file)
    } 
    else { 
      list_species_model_low_accuracy[[name]] <- model
      save(model, file = invalid.model.file)
    }
  } else if (file.exists(valid.model.file)) {
    
    # valid model was previously constructed, load it
    env <- new.env()
    nm <- load(valid.model.file, env)[[1]]
    list_species_model_high_accuracy[[name]] <- env[[nm]]
    
  } else if (file.exists(invalid.model.file)) {
    
    # invalid model was previously constructed, load it
    env <- new.env()
    nm <- load(invalid.model.file)[[1]]
    list_species_model_low_accuracy[[name]] <- env[[nm]]
  }
}
```


The models are now stacked in a list but can be viewed and examined as follows:

```{r plot_importance}
# Select the first model in the list
open_species_model <- list_species_model_high_accuracy[[1]]

# name of the dataset plotted
name <- paste("Variable importance for", names(list_species_model_high_accuracy[1]))

# plot the variable importance
plot(open_species_model, main = name)
```


```{r plot_envelopes}
# plot the response curve to see what the range of important values is per abiotic dataset
response(open_species_model)
```

The outcome of the species distribution models can be used to create a prediction of the areas 
that are suitable for the species. The script below shows a loop that creates prediction raster 
files for the models with a high prediction accuracy.

```{r plot_suitability}
# combine all prediction rasters, either by doing the projection or by reading from a file
prediction_rasters <- stack()
taxon.names <- names(list_species_model_high_accuracy)
for (i in 1:length(list_species_model_high_accuracy) ) {
  
  # file name: load if exists, create otherwise
  valid.model.prediction <- sprintf('%s/results/per_species/%s/valid_maxent_prediction.rda', REPO_HOME, taxon.names[i])
  if( file.exists(valid.model.prediction) ) {
    
    # load file
    message(sprintf("loading prediction for taxon %s from file %s", taxon.names[i], valid.model.prediction))
    env <- new.env()
    nm <- load(valid.model.prediction, envir = env)[[1]]
    prediction_rasters <- stack(prediction_rasters, env[[nm]])
  }
  else {
    message(sprintf("computing prediction for taxon %s, will write to file %s", taxon.names[i], valid.model.prediction))
    open_species_model <- list_species_model_high_accuracy[[i]]
    
    # select non correlated layers from model environment in the world environment
    noncorrelated <- names(open_species_model@presence)
    subsetworldEnv <- subset(currentEnv,noncorrelated)
  
    # make prediction of the whole earth based on the maxent SDM
    species.pred <- predict(open_species_model, subsetworldEnv)
    
    # save file, stack prediction contents
    save(species.pred, file = valid.model.prediction)
    prediction_rasters <- stack(prediction_rasters, species.pred)
  }
}

names(prediction_rasters) <- names(list_species_model_high_accuracy)
plot(prediction_rasters)
```

Now that we have the prediction rasters we can write them to files:

```{r write_predictions}
for ( i in 1:length(names(prediction_rasters)) ) {
  taxon.name <- names(prediction_rasters)[[i]]
  prediction.map.file <- sprintf('%s/results/per_species/%s/prediction_map.pdf', REPO_HOME, taxon.name)
  if ( !file.exists(prediction.map.file) ) {
    pdf(file = prediction.map.file)
    plot(prediction_rasters[[i]])
    dev.off()
  }
}
```

To assess whether the predicted suitable niche spaces differ per species we calculate their niche 
overlap. We use Schoener’s D to calculate niche overlap since it has been suggested to be the best 
suited index for maxent SDM outputs (Rödder & Engler, 2011). The index ranges from 0 which is no 
overlap to 1 which is a complete overlap and is based on the model prediction maps.

```{r calc_dist}
# location of a triangular, inverse distance matrix file
overlap.file <- paste(REPO_HOME, '/results/maxent/overlap.csv', sep = '')
if ( !file.exists(overlap.file) ) {
  
  # file doesn't exist, calculate Schoener's Distance and store file
  overlap <- calc.niche.overlap(prediction_rasters, stat="D", maxent.args )
  write.table(overlap, file = overlap.file, sep = ",", quote = F)
} else {
  
  # file exists, read it
  overlap <- read.table(overlap.file, sep = ",")
}
```

Having calculated the Schoener's D distances, we can now use these to make a symmetrical distance
matrix, and perform a neighbor joining clustering to visualize the distances in niche space.

```{r cluster_dist}
dendrogram.file <- paste(REPO_HOME, '/results/maxent/dendrogram.tree', sep = '')
if ( !file.exists(dendrogram.file) ) {

  # create a distance matrix, i.e. the inverse of the overlap
  dmatrix <- as.dist(1-overlap)

  # plot an unrooted dendrogram
  tree <- nj(dmatrix)
  write.tree(tree, file = dendrogram.file)
} else {
  tree <- read.tree(file = dendrogram.file)
}
```

Now we can assess whether domesticated Ungulates come from specific areas in niche space:

```{r resample_niche_clustering}

# vector of all tips
dom.taxa <- c(
  "Bos_frontalis_gaurus", "Bos_grunniens_mutus", "Bos_javanicus", "Bos_taurus_primigenius",
 	"Bubalus_bubalis_arnee", "Camelus_bactrianus", "Camelus_dromedarius", "Capra_hircus_aegagrus",
 	"Equus_przewalskii", "Equus_africanus", "Lama_glama_guanicoe", "Ovis_aries_orientalis",
 	"Rangifer_tarandus", "Sus_scrofa", "Vicagna_vicugna"
)

# tips in tree
dom.tips <- tree$tip.label[ which(tree$tip.label %in% dom.taxa) ]

all_pw_distances <- function(tree, tip.vector) {

  # calculate size of distance matrix, instantiate vector
  nt <- length(tip.vector)
  nd <- ( ( nt * nt ) - nt ) / 2
  dist.vector <- vector( mode = "numeric", length = nd )
  
  # do all pairwise comparisons
  k <- 1
  max <- nt - 1
  for ( i in 1:max ) {
    min <- i + 1
    for ( j in min:nt ) {
      dist.vector[k] <- fastDist(tree, tip.vector[i], tip.vector[j])
      k <- k + 1
    }
  }
  return(mean(dist.vector))
}

dom.dist <- all_pw_distances(tree, dom.tips)
sam.dist <- vector( mode = "numeric", length = 1000 )
for ( i in 1:1000 ) {
  sam.tips <- sample(tree$tip.label, length(dom.tips), replace = F)
  sam.dist[i] <- all_pw_distances(tree, sam.tips)
}

{hist(sam.dist, xlab = "Mean pairwise distance in sample", col = "lightblue", main = "Domesticated Ungulates cluster in niche space")
abline(v=dom.dist, col = "red")}
```
