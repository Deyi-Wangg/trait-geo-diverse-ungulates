---
title: "Outlying mean index"
author: "Elke Hendrix"
date: "February 28, 2019"
output: html_document
---

Load the required libraries:

```{r load_libs}
library(adehabitatHS, quietly = T)
library(raster, quietly = T)
library(SDMTools, quietly = T)
library(factoextra, quietly = T)
library(ecospat, quietly = T)
library(cluster, quietly = T)
```

Set the location of the root directory of the git repository
```{r globals}
REPO_HOME <- paste(getwd(),'/../',sep='')
```

Import the taxa list 

```{r taxa}
taxa.names <- scan(
  paste(
    REPO_HOME, 
    "/data/filtered/taxa.txt", 
    sep = ""
  ), 
  sep = "\n", 
  what = character()
)
```

Open the abiotic environmental raster layers in the GIS repository:

```{r layers}
# Load bioclim data
gis.layers <- raster::getData(
  "worldclim",
  var = "bio",
  res = 5,
  path = paste(REPO_HOME, "/data/GIS", sep = ""),
  download = T
)

# The location of the TIFF file with the stacked layers described directly above
files.names <- list.files(paste(REPO_HOME, "/data/GIS/5_deg", sep = ""))

# Turn the file names into layer names: strip the prefix (which might include
# the resolution) and strip the file extension
gis.layers.names <- files.names
gis.layers.names <- gsub('current_5arcmin_','',gis.layers.names)
gis.layers.names <- gsub('.tif','',gis.layers.names)

# Combine the layer names with those we've already read from BIOCLIM
gis.layers.names <- c(names(gis.layers),gis.layers.names)

# Iterate over files
for (i in 1:length(files.names)) {
  
  # Stack with previously read layers
  gis.layers <- stack(
    gis.layers,
    
    # Read as raster
    raster(
      
      # Construct file name
      paste(REPO_HOME, "/data/GIS/5_deg/", files.names[i], sep = "")
    )
  )
}

# Apply all names
names(gis.layers) <- gis.layers.names
rm(gis.layers.names, files.names, i)

# Define CRS string
crs.string <- "+proj=longlat +datum=WGS84"
```

The raster layers are transformed to a spatialpixelsdataframe

```{r taxa}
gis.layers.spdf <- as(gis.layers, "SpatialPixelsDataFrame")
sp::proj4string(gis.layers.spdf) <- CRS(crs.string)
```

Transform the csv files with longitude and latitude values to a 
SpatialPointsDataFrame:

```{r SpatialPointDataFrame}
# two spatialPointsDataFrames are made 
# (i) a SpatialPointsDataFrame based on the raw occurence data
# (ii) a SpatialPointsDataFrame based on the MaxEnt projection layers

# (i) raw occurences 

# create an empty SpatialPointDataFrame to populate in the following loop
spdf_raw_occurences <- new(
  "SpatialPointsDataFrame", 
  coords = structure(
    numeric(0), 
    .Dim = c(0L, 2L),
    .Dimnames = list( NULL, c("x", "y") )
  ),  
  bbox = structure(
    c(1,1,1,1), 
    .Dim = c(2L, 2L),                         
    .Dimnames = list( c("x","y"), c("min","max") )
  ),
  proj4string = new( "CRS", projargs = crs.string )
) 

# populate the empty dataframe with lat/lon values from the taxa list
for ( i in length(taxa.names) ) {
  message(taxa.names[i])
  
  csv.file <- sprintf('%s/data/filtered/%s.csv', REPO_HOME, taxa.names[i])
  species_occurence<-as.matrix(read.csv(csv.file))
  name<- paste(taxa.names[i])
  length_df<- NROW(species_occurence)
  bindlonglat<- as.data.frame(cbind(species_occurence[, c("decimal_longitude", "decimal_latitude")]))
  points<- bindlonglat
  points$decimal_longitude<- as.numeric(as.character(points$decimal_longitude))
  points$decimal_latitude<- as.numeric(as.character(points$decimal_latitude))
  coordinates(points)<- ~ decimal_longitude + decimal_latitude
  spdf2<- SpatialPointsDataFrame(points, data.frame(species = rep(name, length_df)), proj4string = CRS)
  proj4string(spdf2) <- CRS("+proj=longlat +datum=WGS84")
  
  spdf_raw_occurences<- rbind(spdf_raw_occurences, spdf2)

}


# (ii) MaxEnt projection layers 

# create an empty SpatialPointDataFrame to populate in the following loop
spdf_MaxEnt <- new(
  "SpatialPointsDataFrame", 
  coords = structure(
    numeric(0), 
    .Dim = c(0L, 2L),
    .Dimnames = list( NULL, c("x", "y") )
  ),  
  bbox = structure(
    c(1,1,1,1), 
    .Dim = c(2L, 2L),                         
    .Dimnames = list( c("x","y"), c("min","max") )
  ),
  proj4string = new( "CRS", projargs = crs.string )
) 

# populate the empty dataframe with lat/lon values from the taxa list
for ( i in 1:length(taxa.names) ) {
  message(taxa.names[i])
  
  # construct file name
  valid.model.prediction <- sprintf(
    "%s/results/per_species/%s/valid_maxent_prediction.rda", 
    REPO_HOME, 
    taxa.names[i]
  )
  
  # load model prediction
  env <- new.env()
  nm <- load(valid.model.prediction, envir = env)[[1]]
  raster <- env[[nm]]
  
  # threshold the prediction and retain the remaining points in SPDF
  raster[raster == 0] <- NA
  points <- rasterToPoints( raster, spatial=F )
  spdf2 <- SpatialPointsDataFrame(
    points[,-3], 
    data.frame( species = rep( taxa.names[i], nrow(points) ) )
  )
  proj4string(spdf2) <- CRS(crs.string)
  spdf_MaxEnt <- rbind(spdf_MaxEnt, spdf2)
}

rm(i,nm,valid.model.prediction,env,raster,spdf2,points, species_occurence, csv.file, gis.layers, bindlonglat)


```

Two data frames are constructed:

1. a data frame (dfavail) with the values in the SpatialPixelsDataframe, i.e. 
   the traits 
2. a data frame (dfused) with the amount of occurrences per pixel  

```{r create_dataframes}
# XXX `grid has empty column/rows in dimension 2`

# choose which spdf you want to use (i) raw occurences, (ii) MaxEnt projections 
# (i) spdf_raw_occurences
# (ii) spdf_MaxEnt
cp <- count.points(spdf_raw_occurences, gis.layers.spdf)

dfavail <- slot(gis.layers.spdf, "data")
dfavail <- tibble::rowid_to_column(dfavail, "ID")
dfavail <- na.omit(dfavail)

dfused <- slot(cp, "data")
dfused <- tibble::rowid_to_column(dfused, "ID")

dfused <- subset(dfused, dfused$ID %in% dfavail$ID )
dfused <- subset(dfused, select = -ID )


```

A PCA analysis is conducted to standardize all the environmental variables. 
This standardized dataframe is used a an input dataset for the niche function to calculate the OMI per species. The OMI is used to plot both niche breadth and niche position per species. 

```{r PCA_analysis}
dud <- dudi.pca(dfavail[2:42], scannf=F)
rm(dfavail, cp)

```


```{r OMI_analysis}
nic<- niche(dud, dfused, scannf=F)

# shows the averages per species for the standardized environmental variables
p <- nic$tab

# write to file
normalized.csv <- paste(REPO_HOME, "/results/OMI/normalized_raw_values.csv", sep="")
write.csv(p, normalized.csv)

# clean up
rm(p,nic)
```

calculate gower's distance

```{r gowers_distance}
# load the normalized values from the github
normalized.repo <- paste(REPO_HOME, '/results/OMI/normalized_raw_values.csv', sep = '')
normalized.values <- read.csv(normalized.repo)

# set names of species to rownames
tree.withouthnames <- normalized.values[,-1]
rownames(tree.withouthnames) <- normalized.values[,1]

# save gowers dataframe 
overlap.csv <- paste(REPO_HOME, "/results/maxent/gowers_overlap.csv", sep="")
gow <- daisy(tree.withouthnames, metric="gower", stand=FALSE)
gow_df <- as.matrix(gow)

if (!file.exists(overlap.csv)) {
  write.csv(gow_df, overlap.csv)
}

# create tree
# compute distances, i.e. inverse of overlap
distances <- as.dist(gow_df)
hclust.tree <- hclust(distances)
tree <- as.phylo(hclust.tree)

# write tree 
tree.file <- paste(REPO_HOME, "/results/maxent/overlap_gower.tree", sep="")
write.tree(tree, file = tree.file)
```


Now we can assess whether domesticated Ungulates come from specific areas in niche space:

```{r resample_niche_clustering}

# vector of all tips
dom.taxa <- c(
  "Bos_frontalis_gaurus", "Bos_grunniens_mutus", "Bos_javanicus", "Bos_taurus_primigenius",
  "Bubalus_bubalis_arnee", "Camelus_bactrianus", "Camelus_dromedarius", "Capra_hircus_aegagrus",
  "Equus_przewalskii", "Lama_glama_guanicoe", "Ovis_aries_orientalis",
  "Rangifer_tarandus", "Sus_scrofa", "Vicagna_vicugna"
)

# tips in tree
dom.tips <- tree$tip.label[ which(tree$tip.label %in% dom.taxa) ]

# this function calculates the average pairwise patristic distance among an
# input vector of tip labels
mean_pw_distance <- function(tree, tip.vector) {

  # calculate size of distance matrix, instantiate vector
  nt <- length(tip.vector)
  nd <- ((nt * nt) - nt) / 2
  dist.vector <- vector(mode = "numeric", length = nd)

  # do all pairwise comparisons
  k <- 1
  max <- nt - 1
  for (i in 1:max) {
    min <- i + 1
    for (j in min:nt) {
      dist.vector[k] <- phytools::fastDist(tree, tip.vector[i], tip.vector[j])
      k <- k + 1
    }
  }
  return(mean(dist.vector))
}

# calculate average pairwise distance (APD) among domesticates
dom.dist <- mean_pw_distance(tree, dom.tips)

# take random tip samples, compute APD among these many time
sam.num <- 1000
sam.dist <- vector(mode = "numeric", length = sam.num)
for (i in 1:sam.num) {
  sam.tips <- sample(tree$tip.label, length(dom.tips), replace = F)
  sam.dist[i] <- mean_pw_distance(tree, sam.tips)
}


{
  clustering.pdf.file <- sprintf("%s/results/maxent/clustering.pdf", REPO_HOME)
  pdf(file = clustering.pdf.file)
  h <- hist(
    sam.dist,
    xlab = sprintf("Mean pairwise patristic distance in random sample of %i tips (n=%i)", length(dom.tips), sam.num),
    col = "lightblue",
    main = "Domesticated Ungulates cluster in niche space"
  )

  # fit normal distribution
  xfit <- seq(min(sam.dist), max(sam.dist), length = length(sam.dist))
  yfit <- dnorm(xfit, mean = mean(sam.dist), sd = sd(sam.dist))
  yfit <- yfit * diff(h$mids[1:2]) * length(sam.dist)
  lines(xfit, yfit, col = "black", lwd = 2)

  # draw Â± 2 * standard deviation
  abline(v = mean(sam.dist) + 2 * sd(sam.dist), col = "green")
  abline(v = mean(sam.dist) - 2 * sd(sam.dist), col = "green")

  # indicate domesticated APD
  abline(v = dom.dist, col = "red")
  dev.off()
}
```
